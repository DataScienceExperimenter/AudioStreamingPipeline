"""
Real-time audio processing pipeline with performance metrics.
"""

import os
import asyncio
import time
import gc
import numpy as np
import warnings
import uuid
from typing import Dict, Any, Union
from datetime import datetime
from pydantic import BaseModel

# Suppress all warnings
warnings.filterwarnings("ignore")

# Configure logger
try:
    from loguru import logger
    logger.remove()
    logger.add(lambda msg: print(msg, flush=True), level="INFO")
    logger.add("logs/pipeline.log", rotation="10 MB", level="DEBUG", enqueue=True)
except ImportError:
    import logging
    logging.basicConfig(level=logging.INFO)
    logger = logging.getLogger("pipeline")

# Import components from src directory
try:
    from src.core.component import ComponentConfig
    from src.core.pipeline import Pipeline, PipelineConfig
    from src.components.audio_capture import AudioCapture, AudioCaptureConfig
    from src.components.vad import VAD, VADConfig
    from src.components.audio_preprocessing import AudioPreprocessing, AudioPreprocessingConfig
    from src.components.speech_to_text import SpeechToText, SpeechToTextConfig
    from src.components.text_processing import TextProcessing, TextProcessingConfig
    from src.components.response_generator import ResponseGenerator, ResponseGeneratorConfig
    from src.components.text_to_speech import TextToSpeech
except ImportError as e:
    logger.error(f"Error importing components: {str(e)}")
    logger.error("Make sure you're running this script from the project root directory")
    raise

# Performance metrics tracker
class PerformanceTracker:
    def __init__(self):
        self.metrics = {
            "total_time": 0,
            "components": {},
            "start_time": datetime.now().strftime("%H:%M:%S.%f")[:-3]
        }
        self.start_times = {}
        self.total_start_time = None
    
    def start_pipeline(self):
        self.total_start_time = time.time()
        self.metrics = {
            "total_time": 0,
            "components": {},
            "start_time": datetime.now().strftime("%H:%M:%S.%f")[:-3]
        }
    
    def start_component(self, component_name):
        self.start_times[component_name] = time.time()
    
    def end_component(self, component_name):
        if component_name in self.start_times:
            elapsed = time.time() - self.start_times[component_name]
            if component_name not in self.metrics["components"]:
                self.metrics["components"][component_name] = []
            self.metrics["components"][component_name].append(elapsed)
            return elapsed
        return 0
    
    def end_pipeline(self):
        if self.total_start_time:
            self.metrics["total_time"] = time.time() - self.total_start_time
            self.metrics["end_time"] = datetime.now().strftime("%H:%M:%S.%f")[:-3]
            return self.metrics["total_time"]
        return 0
    
    def print_summary(self):
        summary = {
            "total_time": f"{self.metrics['total_time']:.3f}s",
            "start_time": self.metrics["start_time"],
            "end_time": self.metrics.get("end_time", "N/A"),
            "components": {}
        }
        
        for component, times in self.metrics["components"].items():
            avg_time = sum(times) / len(times) if times else 0
            summary["components"][component] = f"{avg_time:.3f}s"
        
        print("\n" + "=" * 50)
        print("ðŸ“Š PERFORMANCE METRICS")
        print("=" * 50)
        print(f"Start time: {summary['start_time']}")
        print(f"End time: {summary['end_time']}")
        print(f"Total processing time: {summary['total_time']}")
        print("\nComponent times:")
        
        for component, time_str in summary["components"].items():
            print(f"  - {component}: {time_str}")
        
        print("=" * 50 + "\n")

# Custom TextToSpeechConfig with required fields
class CustomTextToSpeechConfig(BaseModel):
    name: str = "TextToSpeech"
    model_name: str = "facebook/mms-tts-eng"
    log_level: str = "INFO"
    device: str = "cpu"
    use_streaming: bool = True
    sample_rate: int = 16000
    use_gtts: bool = True
    voice: str = "en-US-Standard-B"
    cache_dir: str = None
    max_text_length: int = 500
    chunk_size: int = 100
    output_dir: str = "output/tts"
    api_enabled: bool = False
    api_auth_required: bool = False
    api_key: str = None

    class Config:
        protected_namespaces = ()

# Simple VAD that always detects speech
class SimpleVAD:
    def __init__(self, config=None, performance_tracker=None):
        self.name = "SimpleVAD"
        self.performance_tracker = performance_tracker
        logger.info("Initializing SimpleVAD (always detects speech)")
    
    async def initialize(self):
        return True
    
    async def process(self, audio_data):
        """Always detect speech to ensure pipeline continues"""
        if self.performance_tracker:
            self.performance_tracker.start_component("VAD")
        
        # Always return True for speech detection
        has_speech = True
        
        if self.performance_tracker:
            elapsed = self.performance_tracker.end_component("VAD")
            logger.info(f"VAD processing time: {elapsed:.3f}s")
        
        return has_speech, audio_data
    
    async def shutdown(self):
        return True

# Component wrapper classes with performance tracking
class AudioCaptureWrapper(AudioCapture):
    def __init__(self, config_dict, performance_tracker=None):
        self.performance_tracker = performance_tracker
        config = AudioCaptureConfig(
            name=config_dict["name"],
            rate=config_dict.get("rate", 16000),
            frames_per_buffer=config_dict.get("frames_per_buffer", 1024),
            channels=config_dict.get("channels", 1),
            format=config_dict.get("format", 8),
            device_index=config_dict.get("device_index"),
            use_mock=False,  # Always use real microphone
            export_audio=config_dict.get("export_audio", True),
            output_dir=config_dict.get("output_dir", "output/audio"),
        )
        super().__init__(config)

    async def initialize(self):
        if self.performance_tracker:
            self.performance_tracker.start_component("AudioCapture_init")

        result = await super().initialize()

        if self.performance_tracker:
            self.performance_tracker.end_component("AudioCapture_init")

        return result

    async def process(self, data):
        if self.performance_tracker:
            self.performance_tracker.start_component("AudioCapture")

        result = await super().process(data)

        if self.performance_tracker:
            elapsed = self.performance_tracker.end_component("AudioCapture")
            logger.info(f"AudioCapture processing time: {elapsed:.3f}s")

        return result

    async def capture_audio(self, duration):
        """Capture audio for the specified duration"""
        if self.performance_tracker:
            self.performance_tracker.start_component("AudioCapture_recording")

        logger.info(f"Capturing audio for {duration} seconds...")

        # Create a buffer to store audio chunks
        audio_buffer = []

        # Start the audio generator
        self.is_running = True
        start_time = time.time()

        try:
            async for audio_chunk in self.audio_generator():
                # Add chunk to buffer
                audio_buffer.append(audio_chunk)

                # Check if we've captured enough audio
                if time.time() - start_time >= duration:
                    break

            # Concatenate all audio chunks
            if audio_buffer:
                audio_data = np.concatenate(audio_buffer)
            else:
                # If no audio was captured, return empty array
                audio_data = np.array([], dtype=np.float32)

            if self.performance_tracker:
                elapsed = self.performance_tracker.end_component("AudioCapture_recording")
                logger.info(f"Audio recording time: {elapsed:.3f}s")

            return audio_data

        except Exception as e:
            logger.error(f"Error capturing audio: {str(e)}")
            import traceback
            logger.error(traceback.format_exc())

            if self.performance_tracker:
                self.performance_tracker.end_component("AudioCapture_recording")

            # Return empty array on error
            return np.array([], dtype=np.float32)

        finally:
            # Stop the audio generator
            self.is_running = False
    
  

class VADWrapper(SimpleVAD):
    """Wrapper for SimpleVAD that always detects speech"""
    
    def __init__(self, config_dict, performance_tracker=None):
        super().__init__(None, performance_tracker)

class AudioPreprocessingWrapper(AudioPreprocessing):
    def __init__(self, config_dict, performance_tracker=None):
        self.performance_tracker = performance_tracker
        config = AudioPreprocessingConfig(
            name=config_dict["name"],
            apply_gain=config_dict.get("apply_gain", True),
            gain_factor=config_dict.get("gain_factor", 3.0),  # Increased gain
            apply_normalization=config_dict.get("apply_normalization", True),
            api_enabled=config_dict.get("api_enabled", False),
            log_level=config_dict.get("log_level", "INFO")
        )
        super().__init__(config)
    
    async def process(self, audio_data):
        if self.performance_tracker:
            self.performance_tracker.start_component("AudioPreprocessing")
        
        result = await super().process(audio_data)
        
        if self.performance_tracker:
            elapsed = self.performance_tracker.end_component("AudioPreprocessing")
            logger.info(f"AudioPreprocessing time: {elapsed:.3f}s")
        
        return result

# Simple Speech-to-Text that returns a fixed response for testing
class SimpleSpeechToText:
    def __init__(self, config=None, performance_tracker=None):
        self.name = "SimpleSpeechToText"
        self.performance_tracker = performance_tracker
        logger.info("Initializing SimpleSpeechToText")
    
    async def initialize(self):
        return True
    
    async def process(self, audio_data):
        if self.performance_tracker:
            self.performance_tracker.start_component("SpeechToText")
        
        # For testing, return a fixed transcription
        transcription = "This is a test of the audio processing pipeline."
        
        if self.performance_tracker:
            elapsed = self.performance_tracker.end_component("SpeechToText")
            logger.info(f"SpeechToText processing time: {elapsed:.3f}s")
        
        return transcription
    
    async def shutdown(self):
        return True

class SpeechToTextWrapper:
    def __init__(self, config_dict, performance_tracker=None):
        self.performance_tracker = performance_tracker
        self.stt = SimpleSpeechToText(None, performance_tracker)
    
    async def initialize(self):
        return await self.stt.initialize()
    
    async def process(self, audio_data):
        return await self.stt.process(audio_data)
    
    async def shutdown(self):
        return await self.stt.shutdown()

class CustomTextProcessing:
    def __init__(self, config=None, performance_tracker=None):
        self.name = "CustomTextProcessing"
        self.performance_tracker = performance_tracker
    
    async def initialize(self):
        return True
    
    def _analyze_sentiment(self, doc):
        return {"score": 0.0, "label": "neutral"}
    
    async def process(self, text: str) -> Dict[str, Any]:
        if self.performance_tracker:
            self.performance_tracker.start_component("TextProcessing")
        
        try:
            result = {
                "processed_text": text,
                "entities": [],
                "intent": "general_query",
                "sentiment": {"score": 0.0, "label": "neutral"}
            }
            
            if self.performance_tracker:
                elapsed = self.performance_tracker.end_component("TextProcessing")
                logger.info(f"TextProcessing time: {elapsed:.3f}s")
            
            return result
        except Exception as e:
            logger.error(f"Error in text processing: {str(e)}")
            
            if self.performance_tracker:
                self.performance_tracker.end_component("TextProcessing")
            
            return {"processed_text": text, "error": str(e)}
    
    async def shutdown(self):
        return True

class TextProcessingWrapper:
    def __init__(self, config_dict, performance_tracker=None):
        self.text_processing = CustomTextProcessing(None, performance_tracker)
    
    async def initialize(self):
        return await self.text_processing.initialize()
    
    async def process(self, text):
        return await self.text_processing.process(text)
    
    async def shutdown(self):
        return await self.text_processing.shutdown()

class SimpleResponseGenerator:
    def __init__(self, config=None, performance_tracker=None):
        self.name = "SimpleResponseGenerator"
        self.performance_tracker = performance_tracker
    
    async def initialize(self):
        return True
    
    async def process(self, data: Union[str, Dict[str, Any]]) -> str:
        if self.performance_tracker:
            self.performance_tracker.start_component("ResponseGenerator")
        
        try:
            # Extract text from input data
            input_text = data
            if isinstance(data, dict):
                input_text = data.get("processed_text", "")
                if not input_text and "transcription" in data:
                    input_text = data["transcription"]
            
            # Generate a simple response
            response = f"I heard: {input_text}. The audio pipeline is working correctly!"
            
            if self.performance_tracker:
                elapsed = self.performance_tracker.end_component("ResponseGenerator")
                logger.info(f"ResponseGenerator time: {elapsed:.3f}s")
            
            return response
        
        except Exception as e:
            logger.error(f"Error generating response: {str(e)}")
            
            if self.performance_tracker:
                self.performance_tracker.end_component("ResponseGenerator")
            
            return "I'm sorry, I encountered an error. Please try again."
    
    async def shutdown(self):
        return True

class ResponseGeneratorWrapper:
    def __init__(self, config_dict, performance_tracker=None):
        self.performance_tracker = performance_tracker
        self.response_generator = SimpleResponseGenerator(None, performance_tracker)
    
    async def initialize(self):
        return await self.response_generator.initialize()
    
    async def process(self, data):
        return await self.response_generator.process(data)
    
    async def shutdown(self):
        return await self.response_generator.shutdown()

class SimpleTextToSpeech:
    def __init__(self, output_dir="output/tts", performance_tracker=None):
        self.output_dir = output_dir
        self.performance_tracker = performance_tracker
        os.makedirs(output_dir, exist_ok=True)
    
    async def initialize(self):
        return True
    
    async def process(self, text: str) -> str:
        if self.performance_tracker:
            self.performance_tracker.start_component("TextToSpeech")
        
        try:
            from gtts import gTTS
            
            # Generate a unique filename
            filename = f"{uuid.uuid4()}.mp3"
            filepath = os.path.join(self.output_dir, filename)
            
            # Generate speech
            loop = asyncio.get_event_loop()
            await loop.run_in_executor(
                None,
                lambda: gTTS(text=text, lang='en').save(filepath)
            )
            
            logger.info(f"Generated speech file: {filepath}")
            
            if self.performance_tracker:
                elapsed = self.performance_tracker.end_component("TextToSpeech")
                logger.info(f"TextToSpeech time: {elapsed:.3f}s")
            
            return filepath
        
        except Exception as e:
            logger.error(f"Error in TTS: {str(e)}")
            
            if self.performance_tracker:
                self.performance_tracker.end_component("TextToSpeech")
            
            return ""
    
    async def shutdown(self):
        return True

class TextToSpeechWrapper:
    def __init__(self, config_dict, performance_tracker=None):
        self.performance_tracker = performance_tracker
        self.simple_tts = SimpleTextToSpeech(
            config_dict.get("output_dir", "output/tts"), 
            performance_tracker
        )
    
    async def initialize(self):
        return await self.simple_tts.initialize()
    
    async def process(self, text: str) -> str:
        if not isinstance(text, str):
            logger.warning(f"Expected string input for TTS, got {type(text)}")
            if isinstance(text, dict) and "response" in text:
                text = text["response"]
            else:
                text = str(text)
        
        # Use the simple TTS implementation
        return await self.simple_tts.process(text)
    
    async def shutdown(self):
        return await self.simple_tts.shutdown()

class CustomPipeline:
    def __init__(self, components=None, performance_tracker=None):
        self.components = components or []
        self.performance_tracker = performance_tracker
        self.name = "CustomPipeline"
    
    async def initialize(self):
        """Initialize all components in the pipeline"""
        for component in self.components:
            try:
                await component.initialize()
            except Exception as e:
                logger.error(f"Error initializing component {component.name}: {str(e)}")
                import traceback
                logger.error(traceback.format_exc())
                return False
        return True
    
    def add_component(self, component):
        """Add a component to the pipeline"""
        self.components.append(component)
    
    async def process(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """Process data through all components in the pipeline"""
        # Start tracking pipeline performance
        if self.performance_tracker:
            self.performance_tracker.start_pipeline()
        
        result = {}
        
        # Extract audio data from the input dictionary
        audio_data = data.get("audio_data")
        if audio_data is None:
            logger.error("No audio data provided")
            return result
        
        try:
            # Process through components
            current_data = audio_data
            
            # VAD (component 0)
            if len(self.components) > 0:
                vad_component = self.components[0]
                has_speech, processed_audio = await vad_component.process(current_data)
                result["has_speech"] = has_speech
                
                if not has_speech:
                    if self.performance_tracker:
                        self.performance_tracker.end_pipeline()
                    return result
                
                current_data = processed_audio
            
            # AudioPreprocessing (component 1)
            if len(self.components) > 1:
                preprocessing_component = self.components[1]
                processed_audio = await preprocessing_component.process(current_data)
                current_data = processed_audio
            
            # SpeechToText (component 2)
            if len(self.components) > 2:
                stt_component = self.components[2]
                transcription = await stt_component.process(current_data)
                result["transcription"] = transcription
                
                if not transcription:
                    if self.performance_tracker:
                        self.performance_tracker.end_pipeline()
                    return result
                
                current_data = transcription
            
            # TextProcessing (component 3)
            if len(self.components) > 3:
                text_processing_component = self.components[3]
                processed_text = await text_processing_component.process(current_data)
                
                if isinstance(processed_text, dict):
                    result.update(processed_text)
                else:
                    result["processed_text"] = processed_text
                
                current_data = result
            
            # ResponseGenerator (component 4)
            if len(self.components) > 4:
                response_generator_component = self.components[4]
                response_data = await response_generator_component.process(current_data)
                
                if isinstance(response_data, dict) and "response" in response_data:
                    result["response"] = response_data["response"]
                    for key, value in response_data.items():
                        if key != "response":
                            result[key] = value
                else:
                    result["response"] = response_data
                
                current_data = result["response"]
            
            # TextToSpeech (component 5)
            if len(self.components) > 5:
                tts_component = self.components[5]
                
                if not isinstance(current_data, str):
                    if isinstance(current_data, dict) and "response" in current_data:
                        current_data = current_data["response"]
                    else:
                        current_data = str(current_data)
                
                speech_file = await tts_component.process(current_data)
                result["speech_file"] = speech_file
            
            # End tracking pipeline performance
            if self.performance_tracker:
                total_time = self.performance_tracker.end_pipeline()
                logger.info(f"Total pipeline processing time: {total_time:.3f}s")
            
            return result
            
        except Exception as e:
            logger.error(f"Error in pipeline processing: {str(e)}")
            import traceback
            logger.error(traceback.format_exc())
            
            if self.performance_tracker:
                self.performance_tracker.end_pipeline()
            
            return result
    
    async def shutdown(self):
        """Shutdown all components in the pipeline"""
        for component in self.components:
            try:
                await component.shutdown()
            except Exception as e:
                logger.error(f"Error shutting down component {component.name}: {str(e)}")
        return True

class RealTimePipeline:
    def __init__(self):
        """Initialize the pipeline with real-time configurations"""
        # Create performance tracker
        self.performance_tracker = PerformanceTracker()
        
        # Create configuration dictionaries
        self.audio_capture_config = {
            "name": "AudioCapture",
            "rate": 16000,
            "frames_per_buffer": 1024,  # Increased buffer size
            "channels": 1,
            "format": 8,  # 16-bit audio (pyaudio.paInt16)
            "device_index": None,
            "export_audio": True,
            "output_dir": "output/audio",
            "log_level": "INFO",
            "api_enabled": False
        }
        
        self.audio_preprocessing_config = {
            "name": "AudioPreprocessing",
            "apply_gain": True,
            "gain_factor": 3.0,  # Increased gain
            "apply_normalization": True,
            "log_level": "INFO",
            "api_enabled": False
        }
        
        self.tts_config = {
            "name": "TextToSpeech",
            "output_dir": "output/tts",
            "use_gtts": True,
            "log_level": "INFO",
            "api_enabled": False
        }
        
        # Create components
        try:
            self.audio_capture = AudioCaptureWrapper(self.audio_capture_config, self.performance_tracker)
            self.vad = VADWrapper(None, self.performance_tracker)  # Using SimpleVAD
            self.audio_preprocessing = AudioPreprocessingWrapper(self.audio_preprocessing_config, self.performance_tracker)
            self.speech_to_text = SpeechToTextWrapper(None, self.performance_tracker)  # Using SimpleSpeechToText
            self.text_processing = TextProcessingWrapper(None, self.performance_tracker)  # Using CustomTextProcessing
            self.response_generator = ResponseGeneratorWrapper(None, self.performance_tracker)  # Using SimpleResponseGenerator
            self.text_to_speech = TextToSpeechWrapper(self.tts_config, self.performance_tracker)  # Using SimpleTextToSpeech
            
            # Create custom pipeline
            self.pipeline = CustomPipeline(performance_tracker=self.performance_tracker)
            
            # Add components to pipeline
            self.pipeline.add_component(self.vad)
            self.pipeline.add_component(self.audio_preprocessing)
            self.pipeline.add_component(self.speech_to_text)
            self.pipeline.add_component(self.text_processing)
            self.pipeline.add_component(self.response_generator)
            self.pipeline.add_component(self.text_to_speech)
        
        except Exception as e:
            logger.error(f"Error initializing pipeline components: {str(e)}")
            import traceback
            logger.error(traceback.format_exc())
            raise
    
    async def initialize(self):
        """Initialize the pipeline"""
        await self.audio_capture.initialize()
        await self.pipeline.initialize()
    
    async def process_microphone(self, duration: int = 10) -> Dict[str, Any]:
        """Process audio from the microphone for the specified duration"""
        # Play a sound to indicate the system is ready to listen
        await self.play_prompt_sound("start")

        # Print a visual prompt
        print("\n" + "=" * 50)
        print("ðŸŽ¤ SPEAK NOW - System is listening...")
        print(f"Listening for {duration} seconds...")
        print("=" * 50 + "\n")

        logger.info(f"Listening for {duration} seconds...")

        # Capture audio for the specified duration
        try:
            # Start audio capture
            audio_data = await self.audio_capture.capture_audio(duration)

            # Process the captured audio
            data = {"audio_data": audio_data}
            result = await self.pipeline.process(data)

            # Log the result
            if result.get("transcription"):
                logger.info(f"Detected speech: {result.get('transcription')}")
                logger.info(f"Response: {result.get('response')}")

                # Play the response
                speech_file = result.get("speech_file")
                if speech_file and os.path.exists(speech_file):
                    await self.play_audio_file(speech_file)
            else:
                logger.info("No speech detected or transcription failed")

        except Exception as e:
            logger.error(f"Error processing microphone input: {str(e)}")
            import traceback
            logger.error(traceback.format_exc())
            result = {}

        # Play a sound to indicate the system has finished listening
        await self.play_prompt_sound("stop")

        # Print a visual prompt
        print("\n" + "=" * 50)
        print("ðŸ›‘ FINISHED LISTENING")
        print("=" * 50 + "\n")

        # Print performance metrics
        self.performance_tracker.print_summary()

        return result
        
        
        
       
    
    async def play_prompt_sound(self, sound_type: str):
        """Play a sound to indicate the system is ready to listen or has finished listening"""
        try:
            # Check if pygame is installed
            try:
                import pygame
                pygame.mixer.init()
                
                # Define sound files
                sound_files = {
                    "start": "assets/start_listening.wav",
                    "stop": "assets/stop_listening.wav"
                }
                
                # Create assets directory if it doesn't exist
                os.makedirs("assets", exist_ok=True)
                
                # Check if sound file exists
                sound_file = sound_files.get(sound_type)
                if sound_file and os.path.exists(sound_file):
                    # Play sound
                    pygame.mixer.Sound(sound_file).play()
                    await asyncio.sleep(0.5)  # Wait for sound to play
                else:
                    # Generate a simple beep using pygame
                    pygame.mixer.quit()
                    pygame.mixer.init(frequency=44100, size=-16, channels=1, buffer=512)
                    
                    if sound_type == "start":
                        # High-pitched beep for start
                        pygame.mixer.Sound(pygame.sndarray.make_sound(
                            np.sin(2 * np.pi * np.arange(44100 * 0.5) * 880 / 44100).astype(np.float32)
                        )).play()
                    else:
                        # Low-pitched beep for stop
                        pygame.mixer.Sound(pygame.sndarray.make_sound(
                            np.sin(2 * np.pi * np.arange(44100 * 0.5) * 440 / 44100).astype(np.float32)
                        )).play()
                    
                    await asyncio.sleep(0.5)  # Wait for sound to play
            
            except ImportError:
                # If pygame is not installed, use a simple print message
                if sound_type == "start":
                    print("\a")  # Terminal bell
                    logger.info("ðŸ”Š BEEP! Start speaking now.")
                else:
                    print("\a")  # Terminal bell
                    logger.info("ðŸ”Š BEEP! Finished listening.")
        
        except Exception as e:
            logger.error(f"Error playing prompt sound: {str(e)}")
    
    async def play_audio_file(self, audio_file: str):
        """Play an audio file"""
        try:
            # Try to play the response using pygame
            import pygame
            pygame.mixer.init()
            
            if audio_file.endswith(".mp3"):
                pygame.mixer.music.load(audio_file)
                pygame.mixer.music.play()
                
                # Wait for the response to finish playing
                while pygame.mixer.music.get_busy():
                    await asyncio.sleep(0.1)
            elif audio_file.endswith(".aiff") or audio_file.endswith(".wav"):
                sound = pygame.mixer.Sound(audio_file)
                sound.play()
                
                # Wait for the sound to finish playing
                duration = sound.get_length()
                await asyncio.sleep(duration)
        except ImportError:
            logger.info(f"Response saved to {audio_file}")
        except Exception as e:
            logger.error(f"Error playing audio: {str(e)}")
            
            # Try using macOS afplay as a fallback
            try:
                import subprocess
                subprocess.run(["afplay", audio_file], check=True)
            except Exception:
                logger.info(f"Response saved to {audio_file}")
    
    async def shutdown(self):
        """Shutdown the pipeline"""
        await self.audio_capture.shutdown()
        await self.pipeline.shutdown()
        gc.collect()

async def main():
    logger.info("=== Real-Time Audio Processing Pipeline ===")

    # Create output directories
    os.makedirs("output/audio", exist_ok=True)
    os.makedirs("output/tts", exist_ok=True)
    os.makedirs("logs", exist_ok=True)

    # Create pipeline
    try:
        pipeline = RealTimePipeline()
    except Exception as e:
        logger.error(f"Failed to create pipeline: {str(e)}")
        return

    try:
        # Initialize pipeline
        await pipeline.initialize()

        # Process microphone input
        logger.info("Processing microphone input...")
        result = await pipeline.process_microphone(duration=10)

        if not result or not result.get("transcription"):
            logger.info("No speech detected or transcription failed")

    except KeyboardInterrupt:
        logger.info("Interrupted by user")
    except Exception as e:
        logger.error(f"Error: {str(e)}")
        import traceback
        logger.error(traceback.format_exc())
    finally:
        # Shutdown pipeline
        if 'pipeline' in locals():
            await pipeline.shutdown()

if __name__ == "__main__":
    # Set environment variables for better performance
    os.environ["OMP_NUM_THREADS"] = "1"
    os.environ["MKL_NUM_THREADS"] = "1"

    # Suppress all warnings at the Python level
    os.environ["PYTHONWARNINGS"] = "ignore"

    # Run the main function
    asyncio.run(main())